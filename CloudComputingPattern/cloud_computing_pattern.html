<!DOCTYPE html>
<html>
  <head>
    <title>Cloud Computing Pattern</title>
    <meta charset="utf-8">
    <style>
      @import url(https://fonts.googleapis.com/css?family=Yanone+Kaffeesatz);
      @import url(https://fonts.googleapis.com/css?family=Droid+Serif:400,700,400italic);
      @import url(https://fonts.googleapis.com/css?family=Ubuntu+Mono:400,700,400italic);

      body { font-family: 'Droid Serif'; }
      h1, h2, h3 {
        font-family: 'Yanone Kaffeesatz';
        font-weight: normal;
      }
      .remark-code, .remark-inline-code { font-family: 'Ubuntu Mono'; }
    </style>
  </head>
  <body>
    <textarea id="source">

class: center, middle

# Cloud Computing Pattern
Tim Steven Meier | FH Bielefeld


---

class: center, middle
# Availability und Performanz
---
# Availability und Performanz


Bei der Availability wird gemessen, wie lange der Server oder System verfügbar ist

Die Verfügbarkeit kann durch Systemfehler, hoher Nutzeranzahl und Angriffen beeinflusst werden


Bei der Performanz eines Systems geht es nicht nur darum, dass das System überhaupt läuft, sondern das es möglichst schnell läuft

Um eine bessere Performanz zu erreichen kann man versuchen das System zu skalieren und die Anzahl der Server und somit die Rechenleistung zu erhöhen
---

### Deployment Stamps
- Kontext:
    - Ein einzelne Instanz eines Servers kann zu Problemen mit der Performanz und Verfügbarkeit führen
    - Ein Server in Amerika führt dazu, dass Nutzer in anderen Teilen der Welt schlechte Latenz haben
- Lösung:
    - Das System kopieren und mehrmals deployen
- Vorteile:
    - Mehrere Server innerhalb einer Region erhöht die Performanz und Verfügbarkeit
    - Verteilt auf der ganzen Welt verbessert die Latenz von Nutzern der ganzen Welt
- Probleme und Überlegungen:
    - Mehr Server erfordern mehr Maintanance und Kosten
    - Routing zu den richtigen Stamps muss eingerichtet werden
---
### Geodes
- Kontext:
    - Eine einzelne Serverregion führt dazu, dass Nutzer auf der ganzen Welt schlechte Latenz haben
- Lösung:
    - __ge__ographical n**odes**
    - ein globaler load balancer verteilt die Aufgaben an die einzelnen Geoden
    - replizierte Datenbanken, die in allen Geoden untereinander konsistent sind 
- Vorteile:
    - niedrige Latenz für Nutzer auf der ganzen Welt(Performanz)
    - Wenn eine Geode abstürzt, dann übernehmen andere dessen Tasks(Availability)
- Probleme und Überlegungen:
    - mehr Server bedeuten mehr Kosten, man muss überlegen in welchen Regionen sich ein Geoden lohnen
    - vielleicht lohnen sich Deployment Stamps mehr, da eine gemeinsame Datenbank nicht immer erwünscht ist, und die Nutzer häufig nicht global verteilt sind
---

### Throttling (Drosselung)
- Kontext:
    - Die Anzahl an Requests an einen Service sind nicht konstant gleich, manchmal werden sie zu groß und der Service wird überlastet
    - In einem solchen Fall wird der Service in der Regel hochgescaled, aber das benötigt Zeit, da die zusätzlichen Server erst hochfahren müssen
- Lösung:
    - In dem Zeitfenster zwischen der hohen Anzahl an Anfragen und den zusätzlichen Servern werden die Anfragen gedrosselt
    - Mehrere Möglichkeiten:
        - Mit dem Queue Based Load Leveling kann es nicht zu einer Überlastung kommen
        - einen Teil der Funktionalität abschalten, damit der Rest funktioniert
- Vorteile:
    - Der Server stürzt nicht an Überlastung ab(Availability) und funktioniert weiter(Performanz)
- Probleme und Überlegungen:
    - Throttling zu implementieren ist nicht schwer, muss allerdings schon bei der Planung des Services beachtet werden
    - Es muss schnell gehandelt werden um Throttling einzuleiten

---
### Queue-Based Load Leveling
- Kontext:
    - Die Anzahl an Requests und Aufgaben pro Sekunde ist sehr variabel
    - Bei Peaks können die Aufgaben nicht schnell genug abgearbeitet werden
- Lösung:
    - Eine Queue zwischen den Requests und den Services, die diese bearbeiten
    - die Anzahl an Aufgaben bleibt konsistenter
- Vorteile:
    - es sind weniger Services nötig, da nicht eine Anzahl an Services benötigt wird, die mit dem Peak zurecht kommt, sondern mit dem durchschnittlichen Aufkommen
- Probleme und Überlegungen:
    - wenn die Queue zu lang wird, es also ein langen Peak an Requests gibt, dann kann man die Anzahl an Services hochscalen
    - Queues sind eine einweg Kommunikation und es gibt keine Response

---
### Queue-Based Load Leveling
.center[![queue_based_load_leveling](./img/queue_based_load_leveling.PNG)]
---

class: center, middle
# Data Managment
---
# Data Managment

Damit die Performanz und Verfügbarkeit bei Operationen mit Daten, wie beim Downloaden und uploaden von Datenbank

Konsistenz der Daten ist wichtig, wenn die Datenbank mehrmals existiert
---

### Cache-Aside

- Kontext:
    - Bei wiederholtem Zugriff auf Daten in einem Datenspeicher lohnt es sich diese in einen Cache zu speichern
- Lösung:
    - Wenn eine Applikation Daten lädt, dann schaut es zuerst im Cache nach, ob diese bereits vorhanden sind
    - Wenn nicht, dann werden diese aus dem Datenspeicher geladen und in den Cache gespeichert
- Vorteile:
    - Schnellerer Zugriff auf die Daten im Cache
    - Weniger Requests auf die Datenbank
- Probleme und Überlegungen:
    - Cache ist nicht immer aktuell
        - Ablaufdatum des Cache
            - lang genug um nicht die gleichen Daten mehrmals aus dem Datenspeicher zu lesen
            - kurz genug um keine veralteten Daten zu haben

---
### Sharding

- Kontext:
    - Ein einzelner Server hat nicht unendlich Speicherplatz
    - Die Zugriffsgeschwindigkeit eines einzelnen Servers auf den Datenspeicher ist limitiert
    - Ein Server ist limitiert mit der Geschwindigkeit des Internets
    - Daten aus unterschiedlichen Ländern dürfen wegen Gesetzen und sollten aus Latenz und Performanz Gründen nicht auf einem Server gespeichert sein
    - Den Datenserver zu kopieren reicht nicht aus um mit jeden der Punkte zu beheben
- Lösung:
    - Sharding: Aufteilen des Datenspeichers in Shards, welche einen Teil der Daten halten
    - Mehrere Varianten:
        - eine zentrale Lookuptabelle, welche weiß, in welchem Shard die Daten gespeichert sind
            - nachschauen wo die Daten steht kostet etwas Zeit
        - Aufteilen der Shards nach Zeiten: Shard A enthält nur Daten aus dem Januar 2020, Shard B enthält Daten aus Februar 2020, etc.
            - einfaches Managment
            - Shards sind wahrscheinlich nicht gleich groß und werden unterschiedlich oft benutzt
---
### Sharding
            
- Vorteile:
    - Möglichkeit einen Datenspeicher zu vergößern wenn ein einzelner Server, bzw. mehrere Kopien des Servers nicht mehr ausreichen
- Probleme und Überlegungen:
    - Beim Aufteilen auf Shards muss man aufpassen, dass Daten die zusammengehören oder häufig zusammen gebraucht werden in die gleichen Shards packt
    - Wenn Queries auf mehrere Shards zugreifen müssen und deswegen langsam sind, kann man das Index Table Pattern verwenden
    - Viele Shards zu managen kann sehr aufwändig werden
    - Datenkonsistenz kann ein Problem werden


---

### Index Table

- Kontext:
    - Für gewöhnlich haben Datenbanken nur einen Primärkey
    - Wenn Daten abgefragt werden, werden diese über den Primärkey abgefragt
    - Was ist aber, wenn man die Daten häufig über andere Felder abfragen möchte?
- Lösung:
    - mehrere Möglichkeiten


---

### Index Table
- komplette Tabelle kopieren und mit anderem Feld als Primärschlüssel umbauen
- Diese Methode ist bei häufigen Änderungen in den Daten oder großen Datenmengen ungeeignet
.center[![index_table1](./img/index_table1.PNG)]

---

### Index Table
- neue Tabelle(Index Tabelle) mit dem Primärschlüssel und dem gewünschten Feld, das gewünschte Feld wird in der neuen Tabelle als Primärschlüssel verwendet
    - weniger Speicher und weniger doppelte Daten
    - allerdings müssen zwei Queries gemacht weden um die gewünschten Daten zu bekommen
.rigth[![index_table2](./img/index_table2.PNG)]

---

### Index Table
- eine Mischung aus beiden; Indextabelle mit dem gewünschten Schlüssel als Primärkey, dem originalen Primärkey zum nachschauen von Daten in der Originaltabelle und die am häufigsten verwendet Felder
    - häufig benutzte Daten können mit einer Query geholt werden
    - andere Daten können über zwei Queries erreicht werden
.center[![index_table3](./img/index_table3.PNG)]



---

### Index Table
- Vorteile:
    - Erhöhte Performanz beim Zugriff auf Daten über einen anderen als den Primärkey
- Probleme und Überlegungen:
    - Mehraufwand durch managen mehrerer Tabellen
    - mögliche Konsistenzprobleme
    - erhöhte Speicherkosten
---
### Materialized View

- Kontext:
    - Komplexe Queries bei der Daten aus verschiedenen Tabellen zusammengebaut werden benötigen viel Zeit
- Lösung:
    - Eine Materialized View erstellen
    - Eine Materialized View baut automatisch eine neue Tabelle zusammen, welche für die komplizierte Query optimiert ist
- Vorteile:
    - Eine Query der Daten ist wesentlich schneller
- Probleme und Überlegungen:
    - Die View muss bei Änderungen der Datenbank neu erstellt werden, was bei vielen Änderungen in der Datenbank zu einem Performanz Problem führen kann
        - In diesem Fall kann die View auch zu regelmäßigen Zeiten erstellt werden, hierbei Konsistenz beachten


---
### Materialized View
.center[![materialized_view](./img/materialized_view.PNG)]

---
### Event Sourcing
- Kontext:
    - CRUD(create, read, update, and delete) wird in der Regel benutzt um Daten zu ändern
    - Wenn zwei Instanzen gleichzeitg auf eine Datei zugreifen und ändern, dann gibt es Konflikte
    - Mit CRUD wird die Datenbank mit jeder Operation belastet1
- Lösung:
    - speichere(append) Events in einem Speicher
    - wenn man den jetzigen Zustand haben möchte, dann wendet man alle Events auf den Ursprung an.
    - häufig mit CQRS implementiert
- Vorteile:
    - durch gespeicherte Events ist Monitoring schon gegeben
    - weniger oder keine Konflikte in den Daten
- Probleme und Überlegungen:
    - Events sind unveränderlich und in der Vergangenheit passiert
    - auf Dauer wird die Anzahl an Events immer größer und der jetzige Zustand wird schwerer zu berechnen -> regelmäßige Snapshots
    - der jetzige Zustand muss immer wieder nue berechnet werden, wodurch es aufwändig ist diesen oft auszugeben
    - Rollback ist kaum möglich -> Compensating transaction


---

### Command and Query Responsibility Segregation (CQRS)

- Kontext: 
    - Unstimmigkeit zwischen der Lese- und Schreibdarstellung der Daten
    - Konflikte bei gleichzeitigen Aktualisierungen
    - Rechte kann man nicht nur für lesen verteilen (Sicherheit)
- Lösung:
    - Read(Query) und Write(Command) durch seperate Interfaces trennen
- Vorteile:
    - man kann die Interfaces getrennt skalieren
    - die Interfaces lassen sich auf ihre Operation feintunen
- Probleme und Überlegungen:
    - Konsistenz zwischen Read und Write model
    - Komplexere Applikation


---

### Static Content Hosting
- Kontext:
    - Webserver enthalten statische Inhalte, wie zum Beispiel Bilder, welche vom Client geladen werden müssen. Dies belastet den Webserver
- Lösung:
    - Ein Speicher für statische Inhalte kann die Requests übernehmen.
- Vorteile:
    - Die Kosten eines Speichers sind viel geringer, als die für einen Server
- Probleme und Überlegungen:
    - Die statischen Daten können von dem Webserver nicht mehr bearbeitet werden
    - Bei wenigen statischen Inhalten lohnt sich das Pattern nicht
    - Es muss beachtet werden, dass nicht jeder Nutzer beliebige Daten aus dem Speicher downloaden kann; Abhilfe mit dem Valet Key Pattern


---

### Static Content Hosting

.center[![static_content_hosting](./img/static_content_hosting.PNG)]

---
### Valet Key
- Kontext:
    - Häufig müssen große Dateien vom Server an den Client gesendet werden, oder andersherum
    - Dabei wird der Webserver allerdings stark belastet
    - Client uploadet/downloadet Daten zu einem Datastore
    - Allerdings sind die Daten im Datastore nicht mehr sicher, da jeder Client auf diese zugreifen kann
- Lösung:
    - Client fragt Resource beim Webserver an
    - Server validiert die Anfrage und sendet einen Key und die Adresse der Resource
    - Client kann mit den Informationen die gewüschte Resource vom Datastore bekommen
- Vorteile:
    - Performanz und Stabilität des Webservers werden geschont
- Probleme und Überlegungen:
    - Der Key muss verschlüsselt an den Client gesendet werden
    - Der Key sollte nur einen kurzen Zeitraum funktionieren und nur wenige Rechte(z.b read/write) geben
    - Die Daten können nicht mehr verändert werden, bevor der Client sie herunterlädt

---
### Valet Key
.center[![valet_key](./img/valet_key.PNG)]

---

class: center, middle
# Design und Implementation
---
# Design und Implementation

Gutes Design umfasst Faktoren, wie Wartbarkeit der Software und Wiederverwendbarkeit einzelner Komponenten

Während der Implementierung können diese Muster helfen eine bessere Softwarequalität zu erreichen

---
### Backends for Frontends

- Problem:
    - Ein Backend für mehrere Frontends(Desktop Browser, Mobile Browser) mit unterschiedlichen Anforderungen
    - Interfaces für Frontends behindern einander und Änderungen am Backend werden zu komplex
- Lösung:
    - Für jedes Frontend ein eigenes Backend
- Vorteile:
    - Das Backend kann auf das Frontend optimiert werden
    - Unterschiedliche Technologien möglich
- Probleme:
    - Duplizierter Code ist sehr wahrscheinlich
    - Umstieg von einem Backend auf mehrere spezialisierte Backends zeitaufwändig

---

### Anti Corruption Layer
- Kontext:
    - Bei der Migration eines alten Systems auf ein neues System werden noch alte Teile der API/DB benötigt
    - Das alte System verwendet jedoch veraltete Technologien und ist nocht mit dem modernen System vereinbar
- Lösung:
    - Eine Schicht, welche das alte System von dem neuen System trennt
    - Das Anti Corruption Layer fungiert als Brücke zwischen den Systemen
- Vorteile:
    - Es ist möglich mit dem neuen System auf die alten Daten zuzugreifen
- Probleme und Überlegungen:
    - Höhere Latenz
    - Das Anti Corruption Layer muss erstellt und gewartet werden

---

### Anti Corruption Layer
.center[![anti_corruption](./img/anti_corruption.PNG)]
---

### Strangler
- Kontext:
    - Ein System, welches über Jahre erstellt wurde wird schwer zu warten und veraltet
    - Das System in einem Stück komplett neu aufzubauen ist eine viel zu große Aufgabe
- Lösung:
    - Nach und nach Teile des Systems austauschen
    - Eine neue Schicht, die "Strangler Facade", verbindet den neuen und alten Code
- Vorteile:
    - Die Migration auf ein modernes System kann während des normalen Betriebs laufen
- Probleme und Überlegungen:
    - Die Strangler Facade kann zu einem Performance Bottleneck werden


---

### Strangler
.center[![strangler](./img/strangler.PNG)]

---

### External Configuration Store
- Kontext:
    - Lokale Konfigurationsdateien sind auf eine einzelne Applikation limitiert
- Lösung:
    - Externe Konfigurationsdatei
- Vorteile:
    - Die Datei kann von ähnlichen Servern mehrfach benutzt werden
    - Die Konfiguration ist einfacher einzusehen, da die Dateien an der gleichen Stelle liegen
- Probleme und Überlegungen:
    - Der Speicherort muss robust und verfügbar sein
    - Die Dateien müssen geschützt werden, da häufig wichtige Informationen in der Konfiguration stehen
    
---

### Leader Election

- Kontext:
    - Häufig arbeiten mehrere (gleiche) Instanzen zusammen an den gleichen Aufgaben, zum Beispiel bei komplexen Berechnungen
    - Die Instanzen sind durch Scaling kopiert worden
    - Wenn die Instanzen an den gleichen Resource arbeiten ist es möglich, dass diese ihre Ergebnisse gegenseitig überschreiben
- Lösung:
    - Eine Instanz wird zum Anführer gewählt, welcher die anderen koordiniert.
    - Der Code der einzelnen Instanzen ist der gleiche und jede Instanz kann zum Leader werden
    - Es gibt mehrere Wahlmöglichkeiten, zum Beispiel wird die Instanz mit der niedrigsten Prozess ID der Anführer
- Vorteile:
    - Komplexe Aufgaben können koordiniert effizienter und weniger Fehleranfällig ausgeführt werden
- Probleme und Überlegungen:
    - Wenn der Anführer eine Fehlfunktion hat, muss dieser durch einen neuen ersetzt weden
    - Wenn das System durch Scaling wieder kleiner wird, dann muss beachtet werden keinen Leader zu terminieren

---

### Compute Resource Consolidation

- Kontext:
    - Aufteilen von Aufgaben in mehrere Serverinstanzen kann viel Geld kosten, da nicht jede Instanz permanent laufen müsste
- Lösung:
    - Versuchen Idle-time der Instanzen zu verringern indem man jeder Instanz mehr Aufgaben gibt.
    - Dabei kann in eine Instanz ein Task mit viel Arbeitspeicher und wenig CPU Last und ein Task mit viel CPU Last und wenig Arbeitsspeicher
- Vorteile:
    - Spart Geld
    - Aufgaben innerhalb einer Instanz haben eine schnellere Kommunikationsgeschwindigkeit
- Probleme und Überlegungen:
    - Durch hohen Traffic müssen Instanzen gescaled werden; nicht jede Aufgabe ist gleich scalebar und darf somit nicht in der gleichen Instanz laufen
    - Wenn eine Aufgabe innerhalb einer Instanz fehlschlägt, können die anderen Aufgaben der gleichen Instanz mitbetroffen sein
    - Die Instanzen werden komplexer und schwerer zu maintainen

---

class: center, middle
# Messaging
---
# Messaging

Im Cloud Computing gibt es in einem System häufig viele verschiedene Instanzen, die miteinander kommunizieren müssen

Eine gute Infrastruktur ist wichtig um diese Dienste effizient zu verbinden
---

### Asynchronous Request Reply

- Kontext:
    - Für gewöhnlich bekommt man bei Backend Calls innerhalb kürzester Zeit eine Antwort, wodurch die Requests in der Regel synchron sind
    - Manche Requests an das Backend dauern zu lange um synchron zu funktionieren
- Lösung:
    - HTTP Polling
- Vorteile:
    - Alternative zu Verbindungen, welche möglicherweise Stunden laufen müssten
    - HTTP als einzige Technologie, wodurch es in alten Systemen eingebaut werden kann ohne moderne Technolgien
- Probleme und Überlegungen:
    - Wenn eine Resource nicht nach einem Get Befehl zurückgegeben werden sollte, dann wird ein 404 als Antwort erwartet
    - Man kann als Statuscode ein 202 zurückgeben, sollte dabei aber den Ort und eine geschätzte Wartezeit mitgeben, damit der Nutzer an die Resource kommen kann
---

### Asynchronous Request Reply
.center[![async_request_reply](./img/async_request_reply.PNG)]

---
### Scheduler Agent Supervisor
- Kontext:
    - Wenn in einer Applikation mit Remote Services oder Remote Resourcen arbeitet, dann kann es häufig zu Fehlern kommen
    - viele dieser Fehler sind kurzfristiger Natur und können mit dem Retry pattern erneut versucht werden
    - wenn das Problem längerfristig besteht, dann kann sich die Applikation nicht erholen und stürzt ab
    - bei einem Absturz sind einige Schritte vielleicht schon geschehen, welche noch rückgängig gemacht werden müssen
- Lösung:
    - Mehrere Aktoren, die Zugriffe regeln

---
### Scheduler Agent Supervisor
.center[![scheduler_agent_supervisor](./img/scheduler_agent_supervisor.PNG)]
---
### Scheduler Agent Supervisor
- Vorteile:
    - Fehler werden effektiver behandelt
    - Wenn ein Aktor ausfällt können neue gestartet werden, wodurch sich das System selbst heilt
- Probleme und Überlegungen:
    - schwer zu implementieren
    - viele Tests erforderlich
---

### Priority Queue
- Kontext:
    - Für gewöhnlich werden Requests nacheinander abgearbeitet, zum Beispiel mit einer first in first out(FIFO) Queue
    - Wenn es Kunden mit besonderem Status gibt, ist es nötig diesen Priorität zugeben
- Lösung:

---
### Priority Queue
- Man kann in der Queue den einzelnen Requests Prioritäten zuweisen und bei neuen Requests die Queue sortieren
.center[![priority1](./img/priority1.PNG)]

---

### Priority Queue
- Alternativ kann man für jede Priorität eine eigene Queue einrichten.
    - Jede Queue besitzt eigene Services mit der höchsten Rechenpower bei der Queue mit höchster Priorität
    - Als Variation kann man mehrere Queues haben, bei denen die abarbeitenden Services zuerst die Queue mit der höchsten Priorität bedienen
.center[![priority2](./img/priority2.PNG)]
---

### Priority Queue 
- Vorteile:
    - Nutzer oder Tasks mit hoher Priorität werden schneller abgearbeitet
- Probleme und Überlegungen:
    - Mehrere Queues bedeuten potenziell mehr Wartungsbedarf
---
### Choreography
- Kontext:
    - Für gewöhnlich steuert ein Orchestrator die Verteilung von Aufgaben an die einzelnen Services
    - Der Orchestrator hat dadurch eine enge Bindung an alle Services und muss umgeschrieben werden, wenn sich die Services ändern
- Lösung:
    - Publish Subscriber Pattern
    - Client Requests werden in eine Queue gepublished
    - Die einzelnen Services können subscriben und den Request verarbeiten, bei Erfolg wird das Ergebnis wieder für die anderen Services in der Queue gepublished
- Vorteile:
    - Es ist ohne großen Aufwand Services hinzuzufügen, zu ändern oder zu entfernen
    - Der Orchestrator kann kein potenzielles Bottleneck mehr sein
- Probleme und Überlegungen:
    - Fehlerhandling ist komplizierter, weil es keine zentrale Steuereinheit gibt, welche in diesem Fall eingreift


---
### Choreography
.center[![choreography](./img/choreography.PNG)]
---
### Claim Check
- Kontext:
    - In einer auf Messages basierten Architektur werden viele Messages über einen Message Broker verschickt
    - Zu große Dateien verlangsamen den Service
- Lösung:
    - Inhalt der Message in einen Datenspeicher hochladen und einen Claim Check(Abholschein) verschicken
    - Services, die die Message verarbeiten können über den Abholschein den Inhalt selber abholen
    - (nur bei großen Messages)
- Vorteile:
    - Message Broker wird nicht überlastet
    - es ist möglich Authentifizierungsregeln einzubringen, sodass die Inhalte im Datenspeicher sicherer sind, als im Message Broker
- Probleme und Überlegungen:
    - Datenspeicher wird benutzt und kostet Geld
    - Speichern und Laden von Daten kostet Zeit


---
### Claim Check
.center[![claim_check](./img/claim_check.PNG)]
---
    
### Competing Consumers

- Kontext:
    - Die Anzahl an Nutzer eines Webservices variieren
    - Der Service kann eventuell nicht mit der Menge an Nutzern mithalten
- Lösung:
    - Message Queue
    - Der Nutzer schickt seine Anfrage in eine Queue, mit der alle Nutzer nacheinander bearbeitet werden können
- Vorteile:
    - Der Service wird nicht überlastet, da er immer so viele Requests aus der Queue bearbeiten kann, wie er kann
    - Die Anzahl an Nutzern, die Requests in die Queue schicken und die Anzahl Services, die die Requests aus der Queue bearbeiten ist beliebig skalierbar
    - Wenn ein Service fehlschlägt kann der Request zurück in die Queue, sodass ein anderer Service diese übernehmen kann
- Probleme und Überlegungen:
    - Requests, die Services zum Absturz bringen müssen entfernt werden
    - je nach Anzahl an Nutzern kann eine Message Queue zu wenig sein


---

### Competing Consumers
.center[![competing_consumers](./img/competing_consumers.PNG)]
---

### Sequential Convoy
- Kontext:
    - Häufig müssen mehrere Messages von einem Nutzer in einem einzelnen System bearbeitet werden
    - Das übliche Competing Consumers Pattern würde die einzelnen Messages auf unterschiedliche Services verteilen um diese schneller zu verarbeiten, wodruch diese aber fehlschlagen würden, da die Messages zueinander gehören
- Lösung:
    - Messages, die zueinander gehören mit Kategorien versehen, sodass diese von einem einzelnen Service bearbeitet werden
- Vorteile:
    - Messages die hintereinander bearbeitet werden müssen, werden hintereinander bearbeitet
- Probleme und Überlegungen:
    - Wie kategorisiert man die ankommenden Messages



---
### Publisher/Subscriber

- Kontext:
    - Einzelne Komponenten eines Systems müssen im Falle eines Events anderen Komponenten Bescheid geben
    - Mit Asynchronen Messages kann man die Informationen verteilen, ohne auf Antworten warten zu müssen, aber nicht jeder Service muss die Nachricht überhaupt hören
- Lösung:
    - Services publishen Messages asynchron an einen Channel im Message Broker
    - Der Message Broker verteilt die Messages an die Services, welche den Channel subscribed haben
- Vorteile:
    - Da bei asynchonen Messages nicht auf eine Antwort gewartet wird, können die Services schneller wieder an anderen Aufgaben weiterarbeiten
    - Monitoring und Logging ist durch die Messages vereinfacht
- Probleme und Überlegungen:
    - Für die Sicherheit muss beachtet werden, dass sich nicht jeder jeden Channel subscriben kann
    - Da die Messages asynchron sind, kann man nicht antworten
    - Messages werden vielleicht zu spät verarbeitet, wodurch diese bereits veraltet sein kann


---
### Publisher/Subscriber
.center[![publisher_subscriber](./img/publisher_subscriber.PNG)]
---

---

---

class: center, middle
# Management und Monitoring
---
# Management und Monitoring

Cloud Anwendungen sind schwerer zu überwachen, da man nicht die volle Kontrolle über die Hardware und das Betriebssystem hat

Dennoch ist es wichtig zu überprüfen, ob das System verfügbar ist und im vollen Umfang funktioniert

---

### Health Endpoint Monitoring

- Kontext:
    - Es ist wichtig zu überwachen, ob die Applikationen intakt sind und wo das System zu langsam oder gar nicht mehr läuft
- Lösung:
    - Ein Monitoring System schickt regelmäßige Requests an alle Services
    - In diesem Request werden Tests ausgeführt, die Antwortzeiten und Response Codes überprüft
- Vorteile:
    - Es lässt sich überprüfen, ob die Webservices funktionieren(Monitoring)
- Probleme und Überlegungen:
    - Der Check sollte von einem Standort in der Nähe der Nutzer ausgeführt werden, damit Informationen über die Latenz der Realität entsprechen
    - Sicherheitsrichtlinien müssen bei dem Healthcheck eingehalten werden


---
### Ambassador
- Kontext:
    - legacy Applikations haben nicht immer die Möglichkeit unterschiediche Netzwerkfunktionen zu implementieren
- Lösung:
    - Ein Proxy Server (Ambassador) mit allen Netzwerkfunktionen des Clients
    - Der Proxy kann die Retry, Circuit Breaker Pattern verwenden
    - Proxy kann die Clientapplikation mit Monitoring und Sicherheitsfunktionalitäten erweitern
- Vorteile:
    - generischer Proxy Server, welcher für alle möglichen Sprachen und Frameworks die Netzwerkfunktionen übernehmen kann
- Probleme und Überlegungen:
    - Der Proxy Server beeinflusst die Latenz des Servers


---
### Ambassador
.center[![ambassador](./img/ambassador.PNG)]
---
### Sidecar
- Kontext:
    - Applikationen und Services benötigen häufig Funktionen zum Loggen oder verbinden mit dem Netzwerk
    - Die Funktionen in jedem Service einzeln zu implemntieren ist sehr aufwändig
- Lösung:
    - Ein Sidecar erstellen mit den nötigen Funktionen, welches immer an der Seite seiner Primärapplikation bleibt und zusammen mit der Primärapplikation gelöscht wird
- Vorteile:
    - Sidecar hat seine eigenen technischen Anforderungen und kann unabhängig von der Primärapplikation geupdatet werden
    - durch die Nähe zur Primärapplikation gibt es (fast) keine zusätzliche Latenz
- Probleme und Überlegungen:
    - Das Sidecar ist ein Teil von der Applikation und scaled mit, was eventuell nicht benötigt wird

---

### Gateway Offloading

- Kontext:
    - Manche Funktionen werden von vielen oder sogar allen Services benötigt
    - Wartung der gleichen Funktionen an vielen verschiedenen Stellen ist aufwändig
- Lösung:
    - Authentifizierung, Monitoring, Zertifikate, SSL und mehr in ein gateway
- Vorteile:
    - weniger Aufwand in den einzelnen Services
    - Auslagern von Sicherheitsfunktionen in ein einzelnes System macht es einfacher und effizienter zu managen
- Probleme und Überlegungen:
    - möglicher Single Point of Failure
    - möglicher Flaschenhals
    - Nicht jede Funktion sollte in das Gateway ausgelagert werden, vor allem wenn nur wenige Services die Funktion benötigen


---


### Gateway Aggregation

- Kontext:
    - Für eine Aufgabe des Clients müssen häufig mehrere Services angesprochen werden
    - mehrfach Requests an unterschiedliche Services zu schicken 
- Lösung:
    - statt mehrere Requests an die einzelnen Services nur ein Request an ein Gateway
    - Das Gateway übernimmt die restlichen Requests an die einzelnen Services
- Vorteile:
    - Senkung des Traffics
    - Senkung der Latenz
- Probleme und Überlegungen:
    - möglicher Single Point of Failure
    - möglicher Flaschenhals

---


### Gateway Aggregation
.center[![gateway_aggregation](./img/gateway_aggregation.PNG)]
---

### Gateway Routing

- Kontext:
    - Wenn ein Nutzer verschiedene Services ansprechen muss, dann muss er jeden Endpoint kennen
- Lösung:
    - Anstatt dem Nutzer jeden Endpoint zur Verfügung zu stellen, benutzt man ein Gateway, welches die Requests der Nutzer weiterleitet
- Vorteile:
    - Die einzelnen angebotenen Services können sich ohne großen Aufwand ändern und sind weiterhin über das Gateway erreichbar
    - Es ist dabei auch möglich über das Gateway an interne Endpunkte wie VMs zu verbinden
- Probleme und Überlegungen:
    - möglicher Single Point of Failure
    - möglicher Flaschenhals

    
---

class: center, middle
# Ausfallsicherheit
---
# Ausfallsicherheit

Bei der Ausfallsicherheit geht es darum, dass im Falle eines Fehlers das System nicht vollständig versagt, sondern es möglich ist sich von solchen Fehlern zu erholen

Dabei ist es wichtig einen Fehler zu erkennen und angemessen zu handeln

---
### Retry
- Kontext:
    - Services und Datenbanken können überlastet sein oder kurz disconnected sein, wodurch der Service nicht erreichbar ist
- Lösung:
    - Wenn die Verbindung zu einem Service nicht klappt, kann man es einfach erneut versuchen
    - Linear Retry: alle X sekunden ein weiterer Versuch
    - exponential Retry: 1 sekunde warten, 5sek, 20sek...
- Vorteile:
    - Der Service ist nach weiteren Versuchen vielleicht wieder erreichbar
- Probleme und Überlegungen:
    - Wenn zu viele Retries an einen überlasteteten Service gesendet werden, benötigt dieser länger um sich zu erholen
    - Es ist nie sicher, ob sich der Service tatsächlich erholt, wodurch Retries nichts erreichen

---
### Circuit Breaker
- Kontext:
    - Ein Fehler eines Services kann länger dauern und wiederholtes Versuchen kostet nur Zeit, bringt aber nicht zum Erfolg
- Lösung:
    - Der Circuit Breaker ist ein Proxy, der die letzten Failures des Services überwacht
    - 3 Zustände, welche vom Circuit Breaker gesetzt werden, abhängig von den letzten (Miss-)Erfolgen
- Vorteile:
    - weniger sinnlose Retries
    - mehr Chancen für den Service sich zu erholen, bevor er neue Anfragen bekommt
    - mit geloggten Daten kann man Timeouts neu anpassen, sodass der Server sich besser erholt
- Probleme und Überlegungen:
    - Der Circuit Breaker kann ein Problem falsch einschätzen und Anfragen für längere Zeit blockieren, obwohl der Service nur kurz überlastet war
    - Circuit Breaker sollten nur einen Service überwachen, sodass Anfragen auf intakte Services nicht ebenfalls abgeblockt werden

---
### Circuit Breaker
.center[![circuit_breaker](./img/circuit_breaker.PNG)]
---
### Compensating Transaction
- Kontext:
    - Große Transaktionen dauern lange
    - Wenn diese am Ende fehlschlagen und der alles rückgängig gemacht werden muss, dann kann man nicht einfach wieder den ursprünglichen Zustand annehmen, weil dieser bereits anders sein kann
- Lösung:
    - Anstatt eines Rollbacks auf den alten Stand versucht man die Aktionen zu kompensieren
    - Dafür loggt man die Schritte der Transaktion und erstellt Aktionen, die die ursprüglichen Schritte rückgängig machen
- Vorteile:
    - Es gehen keine Informationen verloren
    - Schritte zum Rückgängig machen können auch parallel verlaufen
- Probleme und Überlegungen:
    - Man muss überlegen, ob ein Fehler in einer Transaktion direkt rückgängig gemacht werden sollte, oder der fehlgeschlagene Schritt erneut veruscht werden sollte(Retry)
    - Der Versuch der Kompensation kann auch fehlschlagen, wo dann eventuell ein Mensch eingreifen sollte

---

### Bulkhead
- Kontext:
    - Wenn ein Service sehr langsam sind und Requests nicht antworten, dann füllen sich die Anzahl an Requests, bis der Server überlastet ist
- Lösung:
    - Bulkhead ist ein Begriff aus dem Schiffsbau, wo das Schiff mehrere Trennwände enthält. Wenn das Schiff ein Loch hat, dann flutet nur eine kleine Sektion des Schiffes
    - Bulkhead Pattern isoliert die einzelnen Services, sodass wenn ein Service langsam ist oder fails, die anderen Services unbeeinträchtigt weiterarbeiten können
    - Es werden für jeden Service nur eine maximale Anzahl an Requests angenommen, sodass selbst bei großer Auslastung eines Services die anderen weiterarbeiten können
- Vorteile:
    - Selbst wenn ein Service fehlschlägt können andere Services weiterarbeiten
    - bei größeren Systemen kann man mehrere Instanzen des gleichen Services benutzen, bei dem jeder Client eine Instanz belegt. Wenn ein Client den Server überlastet, dann betrifft es nur den einen Client, während andere Clients den gleichen Service weiternutzen können
- Probleme und Überlegungen:
    - Es ist nicht immer möglich Services aufzuteilen
    - Es kann schwerer zu managen sein



class: center, middle
# Security
---
# Security

Bei der Sicherheit geht es darum, dass die Daten vor unbefugten Zurgiffen geschützt werden
---
### Gatekeeper

- Kontext:
    - Wenn ein Server mit wichtigen Daten arbeitet und einen hohen Standard an Sicherheit haben muss, dann ist es sinnvoll, wenn der Nutzer nicht direkt mit dem Server kommuniziert
- Lösung:
    - Ein Gatekeeper nimmt Requests entgegen und überprüft diese, bevor er sie weiterschickt.
    - Der Gatekeeper hat dabei so gut wie keine Rechte für irgendwas
    - Wenn ein Hacker einen Angriff startet kommt er zwar an den Gatekeeper dran, hat aber dennoch keinen Zugriff auf den Server
- Vorteile:
    - Eine Sicherheitsschicht, welche Angriffe abwehren kann
- Probleme und Überlegungen:
    - Gatekeeper und Server müssen auf unterschiedlichen VMs laufen
    - Erhöht die Latenz
    - Kann ein Single Point of Failure werden

---

### Gatekeeper
    
.center[![gatekeeper](./img/gatekeeper.PNG)]

---

### Federated Identity

- Kontext:
    - Benutzer mögen es nicht sich für jeden Webservice einen eigenen Account anzulegen
    - Wenn sie das tun, dann benutzen sie häufig die gleichen Einlogdaten und wenn nicht, dann vergessen sie gelegentlich das Passwort, wodurch die Nutzer unzufrieden werden
- Lösung:
    - Auslagern der Authentifikation an Identity Providern wie zum Beispiel google, facebook, github...

- Vorteile:
    - Der Nutzer ist zufrieden, da er keinen neuen Account erstellen muss
    - weniger Arbeit, da keine eigene Nutzerverwaltung erstellt werden muss
- Probleme und Überlegungen:
    - Bei mehreren externen Identifikationsdiensten muss herausgefunden werden, welcher der richtige Dienst für die von User angegebenen Daten

---

### Federated Identity
.center[![federated_identity](./img/federated_identity.PNG)]
    
---

## Quellen
http://en.clouddesignpattern.org/index.php/Main_Page
https://docs.microsoft.com/en-us/azure/architecture/patterns/
---
class: center, middle

# Danke fürs Zuhören

# Habt ihr noch Fragen?
    </textarea>
    <script src="https://remarkjs.com/downloads/remark-latest.min.js">
    </script>
    <script>
      var slideshow = remark.create();
    </script>
  </body>
</html>